{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 1 - Diabetes Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Diabetes.csv')\n",
    "x = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert - Array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Dimention to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                            batch_size = 32,\n",
    "                            shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 768 batches in data loader\n",
      "For one iteration (batch), there is:\n",
      "Data     : torch.Size([32, 7])\n",
      "Labels   : torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} batches in data loader\".format(len(dataset)))\n",
    "for (x, y) in train_loader:\n",
    "    print(\"For one iteration (batch), there is:\")\n",
    "    print(\"Data     : {}\".format(x.shape))\n",
    "    print(\"Labels   : {}\".format(y.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulding Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_features, 5)\n",
    "        self.fc2 = nn.Linear(5, 4)\n",
    "        self.fc3 = nn.Linear(4, 3)\n",
    "        self.fc4 = nn.Linear(3, output_features)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadha\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Create object of Class\n",
    "net = Model(7, 1)\n",
    "criterion = torch.nn.BCELoss(size_average = True)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.1, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200,    Loss: 0.616,   Accuracy: 0.656\n",
      "Epoch: 2/200,    Loss: 0.476,   Accuracy: 0.719\n",
      "Epoch: 3/200,    Loss: 0.405,   Accuracy: 0.812\n",
      "Epoch: 4/200,    Loss: 0.605,   Accuracy: 0.656\n",
      "Epoch: 5/200,    Loss: 0.405,   Accuracy: 0.875\n",
      "Epoch: 6/200,    Loss: 0.484,   Accuracy: 0.781\n",
      "Epoch: 7/200,    Loss: 0.539,   Accuracy: 0.812\n",
      "Epoch: 8/200,    Loss: 0.455,   Accuracy: 0.812\n",
      "Epoch: 9/200,    Loss: 0.398,   Accuracy: 0.812\n",
      "Epoch: 10/200,    Loss: 0.428,   Accuracy: 0.750\n",
      "Epoch: 11/200,    Loss: 0.524,   Accuracy: 0.750\n",
      "Epoch: 12/200,    Loss: 0.596,   Accuracy: 0.625\n",
      "Epoch: 13/200,    Loss: 0.500,   Accuracy: 0.781\n",
      "Epoch: 14/200,    Loss: 0.340,   Accuracy: 0.844\n",
      "Epoch: 15/200,    Loss: 0.585,   Accuracy: 0.719\n",
      "Epoch: 16/200,    Loss: 0.457,   Accuracy: 0.781\n",
      "Epoch: 17/200,    Loss: 0.293,   Accuracy: 0.906\n",
      "Epoch: 18/200,    Loss: 0.436,   Accuracy: 0.812\n",
      "Epoch: 19/200,    Loss: 0.404,   Accuracy: 0.812\n",
      "Epoch: 20/200,    Loss: 0.470,   Accuracy: 0.719\n",
      "Epoch: 21/200,    Loss: 0.519,   Accuracy: 0.750\n",
      "Epoch: 22/200,    Loss: 0.399,   Accuracy: 0.906\n",
      "Epoch: 23/200,    Loss: 0.369,   Accuracy: 0.750\n",
      "Epoch: 24/200,    Loss: 0.361,   Accuracy: 0.812\n",
      "Epoch: 25/200,    Loss: 0.469,   Accuracy: 0.750\n",
      "Epoch: 26/200,    Loss: 0.452,   Accuracy: 0.781\n",
      "Epoch: 27/200,    Loss: 0.322,   Accuracy: 0.844\n",
      "Epoch: 28/200,    Loss: 0.496,   Accuracy: 0.656\n",
      "Epoch: 29/200,    Loss: 0.223,   Accuracy: 0.875\n",
      "Epoch: 30/200,    Loss: 0.585,   Accuracy: 0.719\n",
      "Epoch: 31/200,    Loss: 0.386,   Accuracy: 0.844\n",
      "Epoch: 32/200,    Loss: 0.410,   Accuracy: 0.719\n",
      "Epoch: 33/200,    Loss: 0.325,   Accuracy: 0.875\n",
      "Epoch: 34/200,    Loss: 0.367,   Accuracy: 0.812\n",
      "Epoch: 35/200,    Loss: 0.510,   Accuracy: 0.844\n",
      "Epoch: 36/200,    Loss: 0.441,   Accuracy: 0.781\n",
      "Epoch: 37/200,    Loss: 0.437,   Accuracy: 0.719\n",
      "Epoch: 38/200,    Loss: 0.691,   Accuracy: 0.625\n",
      "Epoch: 39/200,    Loss: 0.354,   Accuracy: 0.875\n",
      "Epoch: 40/200,    Loss: 0.527,   Accuracy: 0.656\n",
      "Epoch: 41/200,    Loss: 0.359,   Accuracy: 0.812\n",
      "Epoch: 42/200,    Loss: 0.464,   Accuracy: 0.625\n",
      "Epoch: 43/200,    Loss: 0.380,   Accuracy: 0.844\n",
      "Epoch: 44/200,    Loss: 0.592,   Accuracy: 0.719\n",
      "Epoch: 45/200,    Loss: 0.345,   Accuracy: 0.875\n",
      "Epoch: 46/200,    Loss: 0.520,   Accuracy: 0.656\n",
      "Epoch: 47/200,    Loss: 0.432,   Accuracy: 0.750\n",
      "Epoch: 48/200,    Loss: 0.479,   Accuracy: 0.719\n",
      "Epoch: 49/200,    Loss: 0.457,   Accuracy: 0.812\n",
      "Epoch: 50/200,    Loss: 0.335,   Accuracy: 0.906\n",
      "Epoch: 51/200,    Loss: 0.576,   Accuracy: 0.719\n",
      "Epoch: 52/200,    Loss: 0.328,   Accuracy: 0.844\n",
      "Epoch: 53/200,    Loss: 0.378,   Accuracy: 0.875\n",
      "Epoch: 54/200,    Loss: 0.612,   Accuracy: 0.594\n",
      "Epoch: 55/200,    Loss: 0.313,   Accuracy: 0.875\n",
      "Epoch: 56/200,    Loss: 0.339,   Accuracy: 0.812\n",
      "Epoch: 57/200,    Loss: 0.561,   Accuracy: 0.688\n",
      "Epoch: 58/200,    Loss: 0.525,   Accuracy: 0.625\n",
      "Epoch: 59/200,    Loss: 0.343,   Accuracy: 0.812\n",
      "Epoch: 60/200,    Loss: 0.569,   Accuracy: 0.562\n",
      "Epoch: 61/200,    Loss: 0.319,   Accuracy: 0.844\n",
      "Epoch: 62/200,    Loss: 0.528,   Accuracy: 0.719\n",
      "Epoch: 63/200,    Loss: 0.391,   Accuracy: 0.781\n",
      "Epoch: 64/200,    Loss: 0.372,   Accuracy: 0.781\n",
      "Epoch: 65/200,    Loss: 0.349,   Accuracy: 0.781\n",
      "Epoch: 66/200,    Loss: 0.675,   Accuracy: 0.594\n",
      "Epoch: 67/200,    Loss: 0.290,   Accuracy: 0.906\n",
      "Epoch: 68/200,    Loss: 0.429,   Accuracy: 0.844\n",
      "Epoch: 69/200,    Loss: 0.493,   Accuracy: 0.688\n",
      "Epoch: 70/200,    Loss: 0.257,   Accuracy: 0.938\n",
      "Epoch: 71/200,    Loss: 0.514,   Accuracy: 0.719\n",
      "Epoch: 72/200,    Loss: 0.355,   Accuracy: 0.781\n",
      "Epoch: 73/200,    Loss: 0.385,   Accuracy: 0.781\n",
      "Epoch: 74/200,    Loss: 0.494,   Accuracy: 0.781\n",
      "Epoch: 75/200,    Loss: 0.680,   Accuracy: 0.688\n",
      "Epoch: 76/200,    Loss: 0.332,   Accuracy: 0.875\n",
      "Epoch: 77/200,    Loss: 0.265,   Accuracy: 0.875\n",
      "Epoch: 78/200,    Loss: 0.460,   Accuracy: 0.719\n",
      "Epoch: 79/200,    Loss: 0.326,   Accuracy: 0.875\n",
      "Epoch: 80/200,    Loss: 0.208,   Accuracy: 0.938\n",
      "Epoch: 81/200,    Loss: 0.379,   Accuracy: 0.781\n",
      "Epoch: 82/200,    Loss: 0.541,   Accuracy: 0.688\n",
      "Epoch: 83/200,    Loss: 0.397,   Accuracy: 0.812\n",
      "Epoch: 84/200,    Loss: 0.437,   Accuracy: 0.781\n",
      "Epoch: 85/200,    Loss: 0.311,   Accuracy: 0.906\n",
      "Epoch: 86/200,    Loss: 0.370,   Accuracy: 0.781\n",
      "Epoch: 87/200,    Loss: 0.594,   Accuracy: 0.656\n",
      "Epoch: 88/200,    Loss: 0.533,   Accuracy: 0.688\n",
      "Epoch: 89/200,    Loss: 0.385,   Accuracy: 0.812\n",
      "Epoch: 90/200,    Loss: 0.416,   Accuracy: 0.750\n",
      "Epoch: 91/200,    Loss: 0.424,   Accuracy: 0.844\n",
      "Epoch: 92/200,    Loss: 0.355,   Accuracy: 0.812\n",
      "Epoch: 93/200,    Loss: 0.302,   Accuracy: 0.906\n",
      "Epoch: 94/200,    Loss: 0.410,   Accuracy: 0.844\n",
      "Epoch: 95/200,    Loss: 0.387,   Accuracy: 0.812\n",
      "Epoch: 96/200,    Loss: 0.419,   Accuracy: 0.719\n",
      "Epoch: 97/200,    Loss: 0.527,   Accuracy: 0.719\n",
      "Epoch: 98/200,    Loss: 0.535,   Accuracy: 0.688\n",
      "Epoch: 99/200,    Loss: 0.508,   Accuracy: 0.812\n",
      "Epoch: 100/200,    Loss: 0.499,   Accuracy: 0.750\n",
      "Epoch: 101/200,    Loss: 0.519,   Accuracy: 0.688\n",
      "Epoch: 102/200,    Loss: 0.363,   Accuracy: 0.812\n",
      "Epoch: 103/200,    Loss: 0.411,   Accuracy: 0.844\n",
      "Epoch: 104/200,    Loss: 0.467,   Accuracy: 0.781\n",
      "Epoch: 105/200,    Loss: 0.338,   Accuracy: 0.812\n",
      "Epoch: 106/200,    Loss: 0.510,   Accuracy: 0.781\n",
      "Epoch: 107/200,    Loss: 0.397,   Accuracy: 0.875\n",
      "Epoch: 108/200,    Loss: 0.271,   Accuracy: 0.781\n",
      "Epoch: 109/200,    Loss: 0.465,   Accuracy: 0.781\n",
      "Epoch: 110/200,    Loss: 0.624,   Accuracy: 0.688\n",
      "Epoch: 111/200,    Loss: 0.497,   Accuracy: 0.750\n",
      "Epoch: 112/200,    Loss: 0.494,   Accuracy: 0.875\n",
      "Epoch: 113/200,    Loss: 0.350,   Accuracy: 0.844\n",
      "Epoch: 114/200,    Loss: 0.440,   Accuracy: 0.750\n",
      "Epoch: 115/200,    Loss: 0.295,   Accuracy: 0.906\n",
      "Epoch: 116/200,    Loss: 0.520,   Accuracy: 0.781\n",
      "Epoch: 117/200,    Loss: 0.385,   Accuracy: 0.844\n",
      "Epoch: 118/200,    Loss: 0.250,   Accuracy: 0.875\n",
      "Epoch: 119/200,    Loss: 0.352,   Accuracy: 0.844\n",
      "Epoch: 120/200,    Loss: 0.317,   Accuracy: 0.875\n",
      "Epoch: 121/200,    Loss: 0.353,   Accuracy: 0.906\n",
      "Epoch: 122/200,    Loss: 0.340,   Accuracy: 0.875\n",
      "Epoch: 123/200,    Loss: 0.314,   Accuracy: 0.938\n",
      "Epoch: 124/200,    Loss: 0.486,   Accuracy: 0.750\n",
      "Epoch: 125/200,    Loss: 0.296,   Accuracy: 0.906\n",
      "Epoch: 126/200,    Loss: 0.454,   Accuracy: 0.625\n",
      "Epoch: 127/200,    Loss: 0.352,   Accuracy: 0.781\n",
      "Epoch: 128/200,    Loss: 0.378,   Accuracy: 0.719\n",
      "Epoch: 129/200,    Loss: 0.312,   Accuracy: 0.812\n",
      "Epoch: 130/200,    Loss: 0.556,   Accuracy: 0.781\n",
      "Epoch: 131/200,    Loss: 0.358,   Accuracy: 0.906\n",
      "Epoch: 132/200,    Loss: 0.373,   Accuracy: 0.750\n",
      "Epoch: 133/200,    Loss: 0.395,   Accuracy: 0.781\n",
      "Epoch: 134/200,    Loss: 0.541,   Accuracy: 0.781\n",
      "Epoch: 135/200,    Loss: 0.468,   Accuracy: 0.719\n",
      "Epoch: 136/200,    Loss: 0.283,   Accuracy: 0.938\n",
      "Epoch: 137/200,    Loss: 0.371,   Accuracy: 0.812\n",
      "Epoch: 138/200,    Loss: 0.436,   Accuracy: 0.844\n",
      "Epoch: 139/200,    Loss: 0.389,   Accuracy: 0.781\n",
      "Epoch: 140/200,    Loss: 0.329,   Accuracy: 0.844\n",
      "Epoch: 141/200,    Loss: 0.512,   Accuracy: 0.656\n",
      "Epoch: 142/200,    Loss: 0.473,   Accuracy: 0.688\n",
      "Epoch: 143/200,    Loss: 0.400,   Accuracy: 0.719\n",
      "Epoch: 144/200,    Loss: 0.437,   Accuracy: 0.781\n",
      "Epoch: 145/200,    Loss: 0.294,   Accuracy: 0.844\n",
      "Epoch: 146/200,    Loss: 0.485,   Accuracy: 0.750\n",
      "Epoch: 147/200,    Loss: 0.403,   Accuracy: 0.812\n",
      "Epoch: 148/200,    Loss: 0.397,   Accuracy: 0.750\n",
      "Epoch: 149/200,    Loss: 0.307,   Accuracy: 0.906\n",
      "Epoch: 150/200,    Loss: 0.570,   Accuracy: 0.656\n",
      "Epoch: 151/200,    Loss: 0.687,   Accuracy: 0.531\n",
      "Epoch: 152/200,    Loss: 0.389,   Accuracy: 0.781\n",
      "Epoch: 153/200,    Loss: 0.461,   Accuracy: 0.844\n",
      "Epoch: 154/200,    Loss: 0.495,   Accuracy: 0.656\n",
      "Epoch: 155/200,    Loss: 0.550,   Accuracy: 0.625\n",
      "Epoch: 156/200,    Loss: 0.303,   Accuracy: 0.875\n",
      "Epoch: 157/200,    Loss: 0.403,   Accuracy: 0.875\n",
      "Epoch: 158/200,    Loss: 0.443,   Accuracy: 0.719\n",
      "Epoch: 159/200,    Loss: 0.509,   Accuracy: 0.656\n",
      "Epoch: 160/200,    Loss: 0.410,   Accuracy: 0.719\n",
      "Epoch: 161/200,    Loss: 0.421,   Accuracy: 0.844\n",
      "Epoch: 162/200,    Loss: 0.402,   Accuracy: 0.656\n",
      "Epoch: 163/200,    Loss: 0.366,   Accuracy: 0.719\n",
      "Epoch: 164/200,    Loss: 0.261,   Accuracy: 0.875\n",
      "Epoch: 165/200,    Loss: 0.445,   Accuracy: 0.812\n",
      "Epoch: 166/200,    Loss: 0.312,   Accuracy: 0.781\n",
      "Epoch: 167/200,    Loss: 0.312,   Accuracy: 0.875\n",
      "Epoch: 168/200,    Loss: 0.445,   Accuracy: 0.719\n",
      "Epoch: 169/200,    Loss: 0.484,   Accuracy: 0.719\n",
      "Epoch: 170/200,    Loss: 0.384,   Accuracy: 0.875\n",
      "Epoch: 171/200,    Loss: 0.405,   Accuracy: 0.812\n",
      "Epoch: 172/200,    Loss: 0.359,   Accuracy: 0.812\n",
      "Epoch: 173/200,    Loss: 0.435,   Accuracy: 0.781\n",
      "Epoch: 174/200,    Loss: 0.390,   Accuracy: 0.688\n",
      "Epoch: 175/200,    Loss: 0.467,   Accuracy: 0.688\n",
      "Epoch: 176/200,    Loss: 0.450,   Accuracy: 0.781\n",
      "Epoch: 177/200,    Loss: 0.462,   Accuracy: 0.812\n",
      "Epoch: 178/200,    Loss: 0.290,   Accuracy: 0.906\n",
      "Epoch: 179/200,    Loss: 0.325,   Accuracy: 0.781\n",
      "Epoch: 180/200,    Loss: 0.199,   Accuracy: 0.906\n",
      "Epoch: 181/200,    Loss: 0.307,   Accuracy: 0.844\n",
      "Epoch: 182/200,    Loss: 0.285,   Accuracy: 0.938\n",
      "Epoch: 183/200,    Loss: 0.379,   Accuracy: 0.906\n",
      "Epoch: 184/200,    Loss: 0.406,   Accuracy: 0.781\n",
      "Epoch: 185/200,    Loss: 0.422,   Accuracy: 0.812\n",
      "Epoch: 186/200,    Loss: 0.425,   Accuracy: 0.781\n",
      "Epoch: 187/200,    Loss: 0.469,   Accuracy: 0.781\n",
      "Epoch: 188/200,    Loss: 0.658,   Accuracy: 0.594\n",
      "Epoch: 189/200,    Loss: 0.322,   Accuracy: 0.906\n",
      "Epoch: 190/200,    Loss: 0.526,   Accuracy: 0.688\n",
      "Epoch: 191/200,    Loss: 0.423,   Accuracy: 0.750\n",
      "Epoch: 192/200,    Loss: 0.366,   Accuracy: 0.781\n",
      "Epoch: 193/200,    Loss: 0.619,   Accuracy: 0.594\n",
      "Epoch: 194/200,    Loss: 0.457,   Accuracy: 0.750\n",
      "Epoch: 195/200,    Loss: 0.305,   Accuracy: 0.875\n",
      "Epoch: 196/200,    Loss: 0.368,   Accuracy: 0.750\n",
      "Epoch: 197/200,    Loss: 0.639,   Accuracy: 0.688\n",
      "Epoch: 198/200,    Loss: 0.441,   Accuracy: 0.781\n",
      "Epoch: 199/200,    Loss: 0.414,   Accuracy: 0.750\n",
      "Epoch: 200/200,    Loss: 0.395,   Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "for epoch in range(200):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "\n",
    "        # forward prop\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # clear the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "\n",
    "        # update weight\n",
    "        optimizer.step()\n",
    "\n",
    "    # accuracy calculation\n",
    "    output = (outputs > 0.5).float()\n",
    "    accuracy = (output == labels).float().mean()\n",
    "\n",
    "    # priint statistics\n",
    "    print(\"Epoch: {}/{},    Loss: {:.3f},   Accuracy: {:.3f}\".format(epoch+1, epochs, loss, accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1853f96fc0e2086397a223b6c4d8c3dbb05b85906089b92d942fad2dca26a6c8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
